
@article{donoho_higher_2004,
	title = {Higher criticism for detecting sparse heterogeneous mixtures},
	volume = {32},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1085408492},
	doi = {10.1214/009053604000000265},
	abstract = {Higher criticism, or second-level significance testing, is a multiple-comparisons concept mentioned in passing by Tukey. It concerns a situation where there are many independent tests of significance and one is interested in rejecting the joint null hypothesis. Tukey suggested comparing the fraction of observed significances at a given α-level to the expected fraction under the joint null. In fact, he suggested standardizing the difference of the two quantities and forming a z-score; the resulting z-score tests the significance of the body of significance tests. We consider a generalization, where we maximize this z-score over a range of significance levels 0{\textless}α≤α0. We are able to show that the resulting higher criticism statistic is effective at resolving a very subtle testing problem: testing whether n normal means are all zero versus the alternative that a small fraction is nonzero. The subtlety of this “sparse normal means” testing problem can be seen from work of Ingster and Jin, who studied such problems in great detail. In their studies, they identified an interesting range of cases where the small fraction of nonzero means is so small that the alternative hypothesis exhibits little noticeable effect on the distribution of the p-values either for the bulk of the tests or for the few most highly significant tests. In this range, when the amplitude of nonzero means is calibrated with the fraction of nonzero means, the likelihood ratio test for a precisely specified alternative would still succeed in separating the two hypotheses. We show that the higher criticism is successful throughout the same region of amplitude sparsity where the likelihood ratio test would succeed. Since it does not require a specification of the alternative, this shows that higher criticism is in a sense optimally adaptive to unknown sparsity and size of the nonnull effects. While our theoretical work is largely asymptotic, we provide simulations in finite samples and suggest some possible applications. We also show that higher critcism works well over a range of non-Gaussian cases.},
	pages = {962--994},
	number = {3},
	journaltitle = {The Annals of Statistics},
	shortjournal = {Ann. Statist.},
	author = {Donoho, David and Jin, Jiashun},
	urldate = {2019-04-18},
	date = {2004-06},
	langid = {english},
	mrnumber = {MR2065195},
	zmnumber = {1092.62051},
	keywords = {combining many p-values, Multiple comparsions, normalized empirical process, sparse normal means, thresholding},
	file = {Snapshot:/Users/adamelder/Zotero/storage/2CT4DEAE/Donoho and Jin - 2004 - Higher criticism for detecting sparse heterogeneou.html:text/html}
}

@article{mckeague_adaptive_2015,
	title = {An Adaptive Resampling Test for Detecting the Presence of Significant Predictors},
	volume = {110},
	issn = {0162-1459},
	url = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.2015.1095099},
	doi = {10.1080/01621459.2015.1095099},
	abstract = {This article investigates marginal screening for detecting the presence of significant predictors in high-dimensional regression. Screening large numbers of predictors is a challenging problem due to the nonstandard limiting behavior of post-model-selected estimators. There is a common misconception that the oracle property for such estimators is a panacea, but the oracle property only holds away from the null hypothesis of interest in marginal screening. To address this difficulty, we propose an adaptive resampling test ({ART}). Our approach provides an alternative to the popular (yet conservative) Bonferroni method of controlling family-wise error rates. {ART} is adaptive in the sense that thresholding is used to decide whether the centered percentile bootstrap applies, and otherwise adapts to the nonstandard asymptotics in the tightest way possible. The performance of the approach is evaluated using a simulation study and applied to gene expression data and {HIV} drug resistance data.},
	pages = {1422--1433},
	number = {512},
	journaltitle = {Journal of the American Statistical Association},
	shortjournal = {Journal of the American Statistical Association},
	author = {{McKeague}, Ian W. and Qian, Min},
	urldate = {2019-04-18},
	date = {2015-10-02},
	keywords = {Mult\_hyp},
	file = {Accepted Version:/Users/adamelder/Zotero/storage/XZ3IXPR6/McKeague and Qian - 2015 - An Adaptive Resampling Test for Detecting the Pres.pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/D53Q4FKN/01621459.2015.html:text/html}
}

@article{s._holland_improved_1988,
	title = {Improved Bonferroni-Type Multiple Testing Procedures},
	volume = {104},
	doi = {10.1037/0033-2909.104.1.145},
	abstract = {[Correction Notice: An erratum for this article was reported in Vol 104(2) of Psychological Bulletin (see record
2008-06007-001). An error was made in the author note on page 145. Correspondence should be addressed to Burt S. Holland, Department of Statistics, Temple University, Speakman Hall (006-00), Philadelphia, Pennsylvania 19122. Margaret {DiPonzio} Copenhaver is now at Merck Sharp \& Dohme Research Laboratories, West Point, Pennsylvania.] The Bonferroni multiple comparisons procedure is customarily used when doing several simultaneous tests of significance in relatively nonstandard situations in which other methods do not apply. We review some new and improved competitors to the Bonferroni procedure, that although constraining generalized Type I error probability to be at most α, afford increased power in exchange for increased complexity in implementation. An improvement to the weighted form of the Bonferroni procedure is also presented. Several data sets are reanalyzed with the new methods. ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
	pages = {145--149},
	journaltitle = {Psychological Bulletin},
	shortjournal = {Psychological Bulletin},
	author = {S. Holland, Burt and {DiPonzio} Copenhaver, Margaret},
	date = {1988-07-01}
}

@article{szekely_brownian_2009,
	title = {Brownian distance covariance},
	volume = {3},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/euclid.aoas/1267453933},
	doi = {10.1214/09-AOAS312},
	abstract = {Distance correlation is a new class of multivariate dependence coefficients applicable to random vectors of arbitrary and not necessarily equal dimension. Distance covariance and distance correlation are analogous to product-moment covariance and correlation, but generalize and extend these classical bivariate measures of dependence. Distance correlation characterizes independence: it is zero if and only if the random vectors are independent. The notion of covariance with respect to a stochastic process is introduced, and it is shown that population distance covariance coincides with the covariance with respect to Brownian motion; thus, both can be called Brownian distance covariance. In the bivariate case, Brownian covariance is the natural extension of product-moment covariance, as we obtain Pearson product-moment covariance by replacing the Brownian motion in the definition with identity. The corresponding statistic has an elegantly simple computing formula. Advantages of applying Brownian covariance and correlation vs the classical Pearson covariance and correlation are discussed and illustrated.},
	pages = {1236--1265},
	number = {4},
	journaltitle = {The Annals of Applied Statistics},
	shortjournal = {Ann. Appl. Stat.},
	author = {Székely, Gábor J. and Rizzo, Maria L.},
	urldate = {2019-04-18},
	date = {2009-12},
	mrnumber = {MR2752127},
	zmnumber = {1196.62077},
	keywords = {Brownian covariance, dcor, Distance correlation, independence, multivariate},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/PS2GF2LG/Székely and Rizzo - 2009 - Brownian distance covariance.pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/9D9ICQ2A/1267453933.html:text/html}
}

@article{zhang_comment_2015,
	title = {Comment},
	volume = {110},
	issn = {0162-1459},
	url = {https://amstat.tandfonline.com/doi/full/10.1080/01621459.2015.1106403},
	doi = {10.1080/01621459.2015.1106403},
	pages = {1451--1454},
	number = {512},
	journaltitle = {Journal of the American Statistical Association},
	shortjournal = {Journal of the American Statistical Association},
	author = {Zhang, Yichi and Laber, Eric B.},
	urldate = {2019-04-18},
	date = {2015-10-02},
	file = {Snapshot:/Users/adamelder/Zotero/storage/QM9KTJIV/01621459.2015.html:text/html}
}

@article{hochberg_sharper_1988,
	title = {A sharper Bonferroni procedure for multiple tests of significance},
	volume = {75},
	issn = {0006-3444},
	url = {https://academic.oup.com/biomet/article/75/4/800/423177},
	doi = {10.1093/biomet/75.4.800},
	abstract = {Abstract.  A simple procedure for multiple tests of significance based on individual p-values is derived. This simple procedure is sharper than Holm's (1979) se},
	pages = {800--802},
	number = {4},
	journaltitle = {Biometrika},
	shortjournal = {Biometrika},
	author = {Hochberg, Yosef},
	urldate = {2019-04-18},
	date = {1988-12-01},
	langid = {english},
	file = {Snapshot:/Users/adamelder/Zotero/storage/H8WZ9YLC/423177.html:text/html}
}

@article{benjamini_controlling_1995,
	title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
	volume = {57},
	rights = {© 1995 Royal Statistical Society},
	issn = {2517-6161},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1995.tb02031.x},
	doi = {10.1111/j.2517-6161.1995.tb02031.x},
	shorttitle = {Controlling the False Discovery Rate},
	abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate ({FWER}). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses — the false discovery rate. This error rate is equivalent to the {FWER} when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the {FWER} is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
	pages = {289--300},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Benjamini, Yoav and Hochberg, Yosef},
	urldate = {2019-04-18},
	date = {1995},
	langid = {english},
	keywords = {bonferroni-type procedures, familywise error rate, multiple-comparison procedures, p-values},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/AWM5MF4X/Benjamini and Hochberg - 1995 - Controlling the False Discovery Rate A Practical .pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/KIFIL6F8/j.2517-6161.1995.tb02031.html:text/html}
}

@article{holm_simple_1979,
	title = {A Simple Sequentially Rejective Multiple Test Procedure},
	volume = {6},
	doi = {10.2307/4615733},
	abstract = {This paper presents a simple and widely ap- plicable multiple test procedure of the sequentially rejective type, i.e. hypotheses are rejected one at a tine until no further rejections can be done. It is shown that the test has a prescribed level of significance protection against error of the first kind for any combination of true hypotheses. The power properties of the test and a number of possible applications are also discussed.},
	pages = {65--70},
	journaltitle = {Scandinavian Journal of Statistics},
	shortjournal = {Scandinavian Journal of Statistics},
	author = {Holm, Sture},
	date = {1979-01-01}
}

@article{neyman_jerzy_ix._1933,
	title = {{IX}. On the problem of the most efficient tests of statistical hypotheses},
	volume = {231},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rsta.1933.0009},
	doi = {10.1098/rsta.1933.0009},
	abstract = {The problem of testing statistical hypotheses is an old one. Its origin is usually connected with the name of Thomas Bayes, who gave the well-known theorem on the probabilities a posteriori of the possible “causes" of a given event. Since then it has been discussed by many writers of whom we shall here mention two only, Bertrand and Borel, whose differing views serve well to illustrate the point from which we shall approach the subject. Bertrand put into statistical form a variety of hypotheses, as for example the hypothesis that a given group of stars with relatively small angular distances between them as seen from the earth, form a “system” or group in space. His method of attack, which is that in common use, consisted essentially in calculating the probability, P, that a certain character, x, of the observed facts would arise if the hypothesis tested were true. If P were very small, this would generally be considered as an indication that the hypothesis, H, was probably false, and vice versa. Bertrand expressed the pessimistic view that no test of this kind could give reliable results. Borel, however, in a later discussion, considered that the method described could be applied with success provided that the character, x, of the observed facts were properly chosen—were, in fact, a character which he terms “en quelque sorte remarquable.”},
	pages = {289--337},
	number = {694},
	journaltitle = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
	shortjournal = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
	author = {{Neyman Jerzy} and {Pearson Egon Sharpe} and {Pearson Karl}},
	urldate = {2019-05-13},
	date = {1933-02-16},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/VKN92DAL/Neyman Jerzy et al. - 1933 - IX. On the problem of the most efficient tests of .pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/TKPULF83/rsta.1933.html:text/html}
}

@article{dunn_multiple_1961,
	title = {Multiple Comparisons among Means},
	volume = {56},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1961.10482090},
	doi = {10.1080/01621459.1961.10482090},
	abstract = {Methods for constructing simultaneous confidence intervals for all possible linear contrasts among several means of normally distributed variables have been given by Scheffé and Tukey. In this paper the possibility is considered of picking in advance a number (say m) of linear contrasts among k means, and then estimating these m linear contrasts by confidence intervals based on a Student t statistic, in such a way that the overall confidence level for the m intervals is greater than or equal to a preassigned value. It is found that for some values of k, and for m not too large, intervals obtained in this way are shorter than those using the F distribution or the Studentized range. When this is so, the experimenter may be willing to select the linear combinations in advance which he wishes to estimate in order to have m shorter intervals instead of an infinite number of longer intervals.},
	pages = {52--64},
	number = {293},
	journaltitle = {Journal of the American Statistical Association},
	author = {Dunn, Olive Jean},
	urldate = {2019-05-17},
	date = {1961-03-01},
	file = {Snapshot:/Users/adamelder/Zotero/storage/J7Q9S7JP/01621459.1961.html:text/html;Submitted Version:/Users/adamelder/Zotero/storage/M2EZRCNE/Dunn - 1961 - Multiple Comparisons among Means.pdf:application/pdf}
}

@article{dunn_estimation_1959,
	title = {Estimation of the Medians for Dependent Variables},
	volume = {30},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/euclid.aoms/1177706374},
	doi = {10.1214/aoms/1177706374},
	abstract = {Joint intervals of bounded confidence are suggested for the medians of a bivariate population with continuous marginal distributions. The two intervals are of the classic type based on sample order statistics.},
	pages = {192--197},
	number = {1},
	journaltitle = {The Annals of Mathematical Statistics},
	shortjournal = {Ann. Math. Statist.},
	author = {Dunn, Olive Jean},
	urldate = {2019-05-17},
	date = {1959-03},
	mrnumber = {MR103563},
	zmnumber = {0090.36404},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/4598I8GF/Dunn - 1959 - Estimation of the Medians for Dependent Variables.pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/ZVQ62UQ7/1177706374.html:text/html}
}

@book{miller_simultaneous_1981,
	location = {New York},
	edition = {2},
	title = {Simultaneous Statistical Inference},
	isbn = {978-1-4613-8124-2},
	url = {https://www.springer.com/la/book/9781461381242},
	series = {Springer Series in Statistics},
	abstract = {Simultaneous Statistical Inference, which was published originally in 1966 by {McGraw}-Hill Book Company, went out of print in 1973. Since then, it has been available from University Microfilms International in xerox form. With this new edition Springer-Verlag has republished the original edition along with my review article on multiple comparisons from the December 1977 issue of the Journal of the American Statistical Association. This review article covered developments in the field from 1966 through 1976. A few minor typographical errors in the original edition have been corrected in this new edition. A new table of critical points for the studentized maximum modulus is included in this second edition as an addendum. The original edition included the table by K. C. S. Pillai and K. V. Ramachandran, which was meager but the best available at the time. This edition contains the table published in Biometrika in 1971 by G. 1. Hahn and R. W. Hendrickson, which is far more comprehensive and therefore more useful. The typing was ably handled by Wanda Edminster for the review article and Karola Decleve for the changes for the second edition. My wife, Barbara, again cheerfully assisted in the proofreading. Fred Leone kindly granted permission from the American Statistical Association to reproduce my review article. Also, Gerald Hahn, Richard Hendrickson, and, for Biometrika, David Cox graciously granted permission to reproduce the new table of the studentized maximum modulus. The work in preparing the review article was partially supported by {NIH} Grant {ROI} {GM}21215.},
	publisher = {Springer-Verlag},
	author = {Miller, Rupert G. Jr},
	urldate = {2019-06-06},
	date = {1981},
	langid = {english},
	file = {Snapshot:/Users/adamelder/Zotero/storage/PM7WRB22/9781461381242.html:text/html}
}

@article{pan_powerful_2014,
	title = {A Powerful and Adaptive Association Test for Rare Variants},
	volume = {197},
	rights = {Copyright © 2014 by the Genetics Society of America},
	issn = {0016-6731, 1943-2631},
	url = {https://www.genetics.org/content/197/4/1081},
	doi = {10.1534/genetics.114.165035},
	abstract = {This article focuses on conducting global testing for association between a binary trait and a set of rare variants ({RVs}), although its application can be much broader to other types of traits, common variants ({CVs}), and gene set or pathway analysis. We show that many of the existing tests have deteriorating performance in the presence of many nonassociated {RVs}: their power can dramatically drop as the proportion of nonassociated {RVs} in the group to be tested increases. We propose a class of so-called sum of powered score ({SPU}) tests, each of which is based on the score vector from a general regression model and hence can deal with different types of traits and adjust for covariates, e.g., principal components accounting for population stratification. The {SPU} tests generalize the sum test, a representative burden test based on pooling or collapsing genotypes of {RVs}, and a sum of squared score ({SSU}) test that is closely related to several other powerful variance component tests; a previous study (Basu and Pan 2011) has demonstrated good performance of one, but not both, of the Sum and {SSU} tests in many situations. The {SPU} tests are versatile in the sense that one of them is often powerful, although its identity varies with the unknown true association parameters. We propose an adaptive {SPU} ({aSPU}) test to approximate the most powerful {SPU} test for a given scenario, consequently maintaining high power and being highly adaptive across various scenarios. We conducted extensive simulations to show superior performance of the {aSPU} test over several state-of-the-art association tests in the presence of many nonassociated {RVs}. Finally we applied the {SPU} and {aSPU} tests to the {GAW}17 mini-exome sequence data to compare its practical performance with some existing tests, demonstrating their potential usefulness.},
	pages = {1081--1095},
	number = {4},
	journaltitle = {Genetics},
	author = {Pan, Wei and Kim, Junghi and Zhang, Yiwei and Shen, Xiaotong and Wei, Peng},
	urldate = {2019-07-12},
	date = {2014-08-01},
	langid = {english},
	pmid = {24831820},
	keywords = {adaptive {SPU} ({aSPU}) test, genome-wide association study ({GWAS}), score statistic, sequencing data, sum of powered score ({SPU}) test, sum of squared score ({SSU}) test, sum test},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/7LQUE2Z4/Pan et al. - 2014 - A Powerful and Adaptive Association Test for Rare .pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/MF2EXY8V/1081.html:text/html}
}

@article{xu_adaptive_2016,
	title = {An adaptive two-sample test for high-dimensional means},
	volume = {103},
	issn = {0006-3444},
	url = {https://academic.oup.com/biomet/article/103/3/609/1744173},
	doi = {10.1093/biomet/asw029},
	abstract = {{SUMMARY}.  Several two-sample tests for high-dimensional data have been proposed recently, but they are powerful only against certain alternative hypotheses. In},
	pages = {609--624},
	number = {3},
	journaltitle = {Biometrika},
	shortjournal = {Biometrika},
	author = {Xu, Gongjun and Lin, Lifeng and Wei, Peng and Pan, Wei},
	urldate = {2019-07-12},
	date = {2016-09-01},
	langid = {english},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/75SAE8HG/Xu et al. - 2016 - An adaptive two-sample test for high-dimensional m.pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/XXISDRKN/1744173.html:text/html}
}

@article{fan_sure_2006,
	title = {Sure independence screening for ultra-high dimensional feature space},
	abstract = {Variable selection plays an important role in high dimensional statistical modeling which nowa-days appears in many areas and is key to various scientific discoveries. For problems of large scale or dimensionality p, estimation accuracy and computational cost are two top concerns. In a recent paper, Candes and Tao (2007) propose the Dantzig selector using L1 regularization and show that it achieves the ideal risk up to a logarithmic factor log p. Their innovative procedure and remarkable result are challenged when the dimensionality is ultra high as the factor log p can be large and their uniform uncertainty principle can fail. Motivated by these concerns, we introduce the concept of sure screening and propose a sure screening method based on a correlation learning, called the Sure Independence Screening ({SIS}), to reduce dimensionality from high to a moderate scale that is below sample size. In a fairly general asymptotic framework, the {SIS} is shown to have the sure screening property for even exponentially growing dimensionality. As a methodological extension, an iterative {SIS} ({ISIS}) is also proposed to enhance its finite sample performance. With dimension reduced accurately from high to below sample size, variable selection can be improved on both speed and accuracy, and can then be ac-},
	journaltitle = {Journal of the Royal Statistical Society, Series B},
	author = {Fan, Jianqing and Lv, Jinchi},
	date = {2006},
	file = {Citeseer - Full Text PDF:/Users/adamelder/Zotero/storage/2H5KE8ST/Fan and Lv - 2006 - Sure independence screening for ultra-high dimensi.pdf:application/pdf;Citeseer - Snapshot:/Users/adamelder/Zotero/storage/J94YY96Z/summary.html:text/html}
}

@article{huang_adaptive_2006,
	title = {Adaptive {LASSO} for sparse high-dimensional regression},
	volume = {18},
	abstract = {We study the asymptotic properties of the adaptive Lasso estimators in sparse, high-dimensional, linear regression models when the number of covariates may increase with the sample size. We consider variable selection using the adaptive Lasso, where the L 1 norms in the penalty are re-weighted by data-dependent weights. We show that, if a reasonable initial estimator is available, under appropriate conditions, the adaptive Lasso correctly selects covariates with nonzero coefficients with probability converging to one, and that the estimators of nonzero coefficients have the same asymptotic distribution they would have if the zero coefficients were known in advance. Thus, the adaptive Lasso has an oracle property in the sense of J. Fan and R. Li [J. Am. Stat. Assoc. 96, No. 456, 1348–1360 (2001; Zbl 1073.62547)] and J. Fan and H. Peng [Ann. Stat. 32, No. 3, 928–961 (2004; Zbl 1092.62031)]. In addition, under a partial orthogonality condition in which the covariates with zero coefficients are weakly correlated with the covariates with nonzero coefficients, marginal regression can be used to obtain the initial estimator. With this initial estimator, the adaptive Lasso has the oracle property even when the number of covariates is much larger than the sample size.},
	journaltitle = {Statistica Sinica},
	shortjournal = {Statistica Sinica},
	author = {Huang, Jian and Ma, Shuangge and Zhang, Cun-Hui},
	date = {2006-12-01},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/VKBEI36K/Huang et al. - 2006 - Adaptive LASSO for sparse high-dimensional regress.pdf:application/pdf}
}

@article{anderson_permutation_2001,
	title = {Permutation Tests for Linear Models},
	volume = {43},
	rights = {Australian Statistical Publishing Association Inc. 2001},
	issn = {1467-842X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-842X.00156},
	doi = {10.1111/1467-842X.00156},
	abstract = {Several approximate permutation tests have been proposed for tests of partial regression coefficients in a linear model based on sample partial correlations. This paper begins with an explanation and notation for an exact test. It then compares the distributions of the test statistics under the various permutation methods proposed, and shows that the partial correlations under permutation are asymptotically jointly normal with means 0 and variances 1. The method of Freedman \& Lane (1983) is found to have asymptotic correlation 1 with the exact test, and the other methods are found to have smaller correlations with this test. Under local alternatives the critical values of all the approximate permutation tests converge to the same constant, so they all have the same asymptotic power. Simulations demonstrate these theoretical results.},
	pages = {75--88},
	number = {1},
	journaltitle = {Australian \& New Zealand Journal of Statistics},
	author = {Anderson, Marti J. and Robinson, John},
	urldate = {2019-07-30},
	date = {2001},
	langid = {english},
	keywords = {asymptotics, partial correlations, power, resampling.},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/T9AG5LBD/Anderson and Robinson - 2001 - Permutation Tests for Linear Models.pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/L4ZIB8CQ/1467-842X.html:text/html}
}

@article{omelka_testing_2012,
	title = {Testing equality of correlation coefficients in two populations via permutation methods},
	volume = {142},
	issn = {0378-3758},
	url = {http://www.sciencedirect.com/science/article/pii/S0378375811004630},
	doi = {10.1016/j.jspi.2011.12.018},
	abstract = {The present paper investigates the asymptotic behaviour of a studentized permutation test for testing equality of (Pearson) correlation coefficients in two populations. It is shown that this test is asymptotically of exact level and has the same power for contiguous alternatives as the corresponding asymptotic test. As a by-product we specify the assumptions needed for the validity of the permutation test suggested in Sakaori (2002). A small simulation study compares the finite sample properties of the considered tests.},
	pages = {1396--1406},
	number = {6},
	journaltitle = {Journal of Statistical Planning and Inference},
	shortjournal = {Journal of Statistical Planning and Inference},
	author = {Omelka, M. and Pauly, M.},
	urldate = {2019-07-30},
	date = {2012-06-01},
	keywords = {Behrens–Fisher problem, Contiguous alternatives, Pearson correlation coefficient, Permutation tests, Power of a test, Studentized statistics, Two-sample tests},
	file = {ScienceDirect Full Text PDF:/Users/adamelder/Zotero/storage/HELQ8FVS/Omelka and Pauly - 2012 - Testing equality of correlation coefficients in tw.pdf:application/pdf;ScienceDirect Snapshot:/Users/adamelder/Zotero/storage/XBQZU8F7/S0378375811004630.html:text/html}
}

@inproceedings{gupta_inequalitites_1972,
	title = {Inequalitites on the probability content of convex regions for elliptically contoured distributions},
	url = {https://projecteuclid.org/euclid.bsmsp/1200514222},
	abstract = {Project Euclid - mathematics and statistics online},
	eventtitle = {Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 2: Probability Theory},
	publisher = {The Regents of the University of California},
	author = {Gupta, S. Das and Eaton, M. L. and Olkin, I. and Perlman, M. and Savage, L. J. and Sobel, M.},
	urldate = {2019-07-30},
	date = {1972},
	file = {Full Text PDF:/Users/adamelder/Zotero/storage/HEXYGS5F/Gupta et al. - 1972 - Inequalitites on the probability content of convex.pdf:application/pdf;Snapshot:/Users/adamelder/Zotero/storage/GA9LP8RL/1200514222.html:text/html}
}

@article{eaton_concentration_1991,
	title = {Concentration inequalities for multivariate distributions: I. multivariate normal distributions},
	volume = {12},
	issn = {0167-7152},
	url = {http://www.sciencedirect.com/science/article/pii/016771529190004B},
	doi = {10.1016/0167-7152(91)90004-B},
	shorttitle = {Concentration inequalities for multivariate distributions},
	abstract = {Let X ∼ Np(0, Σ), the p-variate normal distribution with mean 0 and positive definite covariance matrix Σ. Anderson (1955) showed that if Σ2 − Σ1 is positive semidefinite then {PΣ}1(C) ⩾ {PΣ}2(C) for every centrally symmetric (− C = C) convex set C⊆Rp. Fefferman, Jodeit and Perlman (1972) extended this result to elliptically contoured distributions. In the present study similar multivariate concentration inequalities are investigated for convex sets C that satisfy a more general symmetry condition, namely invariance under a group G of orthogonal transformations on Rp, as well as for non-convex sets C that are monotonically decreasing with respect to a pre-ordering determined by G. Both new results and counterexamples are presented. Concentration inequalities may be used to convert classical efficiency comparisons, expressed in terms of covariance matrices, into comparisons of probabilities of multivariate regions.},
	pages = {487--504},
	number = {6},
	journaltitle = {Statistics \& Probability Letters},
	shortjournal = {Statistics \& Probability Letters},
	author = {Eaton, Morris L. and Perlman, Michael D.},
	urldate = {2020-01-08},
	date = {1991-12-01},
	langid = {english},
	file = {ScienceDirect Snapshot:/Users/adamelder/Zotero/storage/YVG6KRE5/016771529190004B.html:text/html}
}

@article{anderson_integral_1955,
	title = {The Integral of a Symmetric Unimodal Function over a Symmetric Convex Set and Some Probability Inequalities},
	volume = {6},
	issn = {0002-9939},
	url = {https://www.jstor.org/stable/2032333},
	doi = {10.2307/2032333},
	pages = {170--176},
	number = {2},
	journaltitle = {Proceedings of the American Mathematical Society},
	author = {Anderson, T. W.},
	urldate = {2020-01-09},
	date = {1955}
}